{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d199e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# import sys, re, textwrap\n",
    "# import pickle\n",
    "# import lzma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009de7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a61ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/miniconda3/envs/ctpesto/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import random\n",
    "# from string import ascii_letters\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "# from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import SeqDataset, get_stat_from_dataset\n",
    "from model import RNN\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e57a6f22-284e-40b0-bb58-5018b930a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_encoding import encode_res, all_resnames,encode_location, selected_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967bca4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bd24582",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2e84a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5d24096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_from_dataset1(seq_dataset):\n",
    "    all_locations = []\n",
    "    for i in seq_dataset:\n",
    "        j = i[1].numpy()\n",
    "        all_locations.append(j)\n",
    "    summary = np.sum(np.array(all_locations), axis=0)\n",
    "    report = \"\"\n",
    "    for i, value in enumerate(summary):\n",
    "        stri = f'{selected_locations[i]}: {str(int(value))}\\n'\n",
    "        report += stri\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31dc89",
   "metadata": {},
   "source": [
    "# Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86beb68f-c115-4326-bc6f-709a08980f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "nres = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e670bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SeqDataset(\"../data/data_seq_locations.xz\", nres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56d7d8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31341.,  5065., 12093.,  6399.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stat_from_dataset1(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b332923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the dataset is: 42511\n"
     ]
    }
   ],
   "source": [
    "print(\"length of the dataset is:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d95bdeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(dataset, [len(dataset)-2500, 2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "764ccade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "membrane: 1845\n",
      "cytoplasm: 277\n",
      "mitochondrion: 736\n",
      "nucleus: 380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(get_stat_from_dataset1(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45b793",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, device):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, \n",
    "                            batch_first=True, dropout=0.1)\n",
    "#         self.gru = nn.GRU(input_size, self.hidden_size, self.num_layers, batch_first=True, dropout=0.2)\n",
    "#         self.fc1 = nn.Linear(hidden_size, int(hidden_size/2))\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(int(hidden_size/2), int(hidden_size/2))\n",
    "#         self.fc3 = nn.Linear(int(hidden_size/2), num_classes)\n",
    "        self.hidden2tag = nn.Linear(self.hidden_size, num_classes)\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).float()).to(self.device)\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).float()).to(self.device)\n",
    "        out, _ = self.lstm(x, (h0,c0)) \n",
    "#         out = self.relu(self.fc1(out[:, -1, :]))\n",
    "#         out = self.relu(self.fc2(out))\n",
    "#         out = self.fc3(out) \n",
    "        tag_space = self.hidden2tag(out[:, -1, :])\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fefd9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_letters = len(all_resnames)\n",
    "n_categories = len(selected_locations)\n",
    "learning_rate = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(nres, 64, 4, n_categories, device=device)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc272d08",
   "metadata": {},
   "source": [
    "### test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aeccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset,batch_size=12)\n",
    "X = next(iter(dataloader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11938923",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to(device)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca853893",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e2901",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127848b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        x = X.to(device)\n",
    "        y = Y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            x = X.to(device)\n",
    "            y = Y.to(device)\n",
    "            pred = model(x)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "#             correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "#     correct /= size\n",
    "#     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a4994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=256)\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset,batch_size=20)\n",
    "x,y = next(iter(dataloader))\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7801a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(x)\n",
    "y_pred\n",
    "a = torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81da5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nn.Softmax()\n",
    "b(y_pred).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1580c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
